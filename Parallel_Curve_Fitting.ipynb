{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNFPTYRxdFE50YqI3XWvG3a"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Parallel Curve Fitting Notebook\n","\n","#### This notebook is used to perform a parallelized non-linear least squares Lorentzian fit of the noisy Hyperspectral Optical Micrscope curves. The peak height, width, and position are then measured and saved for each data file from 0 - 15 minutes of UV-Ozone Oxidation and plotted to observe a trend in the evolution in these parameters over time. The functions generated from the allometric fitting of the peak fit parameters is then used to generate the synthetic data"],"metadata":{"id":"d3Q9xkve5CNo"}},{"cell_type":"markdown","source":["# Load in Libraries"],"metadata":{"id":"HZ2-H6StEKj-"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"WV2Y5vZN3_B5"},"outputs":[],"source":["import hyperspy.api as hs\n","import hyperspy.signal_tools as hs_st\n","import hyperspy.axes as axes\n","import numpy as np\n","import matplotlib as mpl\n","import matplotlib.pyplot as plt\n","from hyperspy.signals import Signal1D\n","from tqdm import tqdm\n","import csv\n","from scipy.optimize import curve_fit\n","from lmfit.models import LorentzianModel\n","from sklearn.cluster import KMeans\n","import os\n","from lmfit.models import LorentzianModel\n","from joblib import Parallel, delayed\n","\n","hs.set_log_level('INFO')"]},{"cell_type":"markdown","source":["# Define Functions for Loading/Processing Data and Fitting Curves"],"metadata":{"id":"Fru0_kRREpUH"}},{"cell_type":"code","source":["def loadFiles(title, size_arr, size_sel):\n","    \"\"\"\n","    Function to load the files and crop them to the correct size.\n","\n","    Args:\n","        title: The title of the file to be loaded\n","        size_arr: The array containing the size of the crop\n","        size_sel: The index of the size\n","    Returns:\n","        s0.data: 3D Hyperspy data array of size (300, 300, n_wavelengths)\n","    \"\"\"\n","    #Image frame select and loading\n","    s0 = hs.load(title) # load the file\n","    s0.data = s0.data[::-1] # the file needs to be transposed to solve an issue with the array dimensions.\n","\n","    s0.crop(1,size_arr[size_sel][0][0], size_arr[size_sel][0][1])\n","    s0.crop(2,size_arr[size_sel][1][0], size_arr[size_sel][1][1])\n","\n","    # set titles and name variables.\n","    s0 = s0.as_signal1D(0)\n","    s0.axes_manager[0].name = \"width\"\n","    s0.axes_manager[1].name = \"height\"\n","    s0.axes_manager[2].name = \"wavelength\"\n","    s0.axes_manager[0].units = \"pix\"\n","    s0.axes_manager[1].units = \"pix\"\n","    s0.axes_manager[2].units = \"nm\"\n","    s0.axes_manager[2].offset = 200\n","    s0.axes_manager[2].scale = 4\n","\n","    return s0.data\n","\n","def subtract_background(data):\n","    \"\"\"\n","    Subtract the background signal from the DRS data. Use the first 20 and last 20\n","    points of the spectrum to calculate the background signal.\n","\n","    Args:\n","        data: The data array to be processed\n","    Returns:\n","        data: Background subtracted data array of the same length\n","    \"\"\"\n","    x = np.arange(len(data))\n","    background_indices = np.concatenate((np.arange(20), np.arange(-20, 0)))  # Indices for the background points\n","    background_x = x[background_indices]\n","    background_y = data[background_indices]\n","    background_params = np.polyfit(background_x, background_y, 1)  # Fit a line\n","    background = np.polyval(background_params, x)\n","    return data - background\n","\n","def fit_lorentzian_for_one_peak(data):\n","    \"\"\"\n","    Function to fit a Lorentzian curve to the data.\n","\n","    Args:\n","        data: The data array to be fitted to a lorentzian curve\n","    Returns:\n","        out: The fitted curve\n","    \"\"\"\n","    data = subtract_background(data)\n","    x = np.arange(len(data))\n","\n","    lorentz = LorentzianModel(prefix='l1_')\n","    pars = lorentz.guess(data, x=x)\n","\n","    # Optional parameters can be uncommented to focus the fit around certain values\n","\n","    # pars['l1_center'].set(value=50)\n","    # pars['l1_center'].set(min=10)\n","    # pars['l1_center'].set(max=90)\n","    # pars['l1_sigma'].set(value=0.1)\n","    # pars['l1_sigma'].set(max=15)\n","    # pars['l1_amplitude'].set(value=10)\n","\n","    out = lorentz.fit(data, pars, x=x)\n","    return out\n","\n","def manageData(data):\n","    \"\"\"\n","    Function to output the peak fit parameters from the data in a readable way.\n","\n","    Args:\n","        data: The data array to be processed\n","    Returns:\n","        params['l1_height'], params['l1_center'], params['l1_sigma']: The peak fit parameters\n","    \"\"\"\n","    result = fit_lorentzian_for_one_peak(data)\n","    params = result.params.valuesdict()\n","    return (params['l1_height'], params['l1_center'], params['l1_sigma'])\n","\n","def removeIssuePoint(data):\n","    \"\"\"\n","    Function to remove miscalculation error from HOM.\n","\n","    Args:\n","        data: The data array to be processed\n","    Returns:\n","        data: The data array after correcting the miscalculation\n","    \"\"\"\n","    for x in range(len(data)):\n","        for y in range(len(data[0])):\n","            curMax = np.max(data[x][y])\n","            for z in range(len(data[0][0])):\n","                if data[x][y][z] == curMax:\n","                    data[x][y][z] = data[x][y][z-1] # Replace the miscalculation with the previous value\n","                    break\n","    return data"],"metadata":{"id":"NfJh4jH24F-r"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load in Fully Processed Data and Visualize Curve Fit"],"metadata":{"id":"nCCyyVY4FArq"}},{"cell_type":"code","source":["# Global variables to find triangle of interest from full image\n","size_sel = 1\n","size_arr = [[[345 ,350], [810, 815]], [[216, 516], [675, 975]], [[222, 495], [672, 972]]]\n","\n","# Add names of files to list and load them into a list\n","file_list = []\n","for item in os.listdir('Time Series Oxidation Files'):\n","    if item.endswith('.tif'):\n","        file_list.append(item)\n","\n","data_list = []\n","for item in file_list:\n","    data_list.append(loadFiles(item, size_arr, size_sel))\n","\n","for file in tqdm(data_list):\n","    file = removeIssuePoint(file)"],"metadata":{"id":"tkEPyZdj4ITh"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Use only one pixel to test the code is right or not, by checking the fitted result\n","#####################################################################################################\n","#####################################################################################################\n","\n","# Choose a pixel (e.g., pixel at position (x, y))\n","chosen_pixel = (150,150)\n","chosen_pixel_data = data_list[0][chosen_pixel[0], chosen_pixel[1], :]\n","\n","# Subtract background from chosen pixel data\n","chosen_pixel_data_subtracted = subtract_background(chosen_pixel_data)\n","\n","# Fit Lorentzian to the chosen pixel data\n","result = fit_lorentzian_for_one_peak(chosen_pixel_data)\n","params = result.params.valuesdict()\n","print(params)\n","\n","# Plot original and fitted curve for the chosen pixel\n","plt.figure(figsize=(8, 6))\n","plt.plot(chosen_pixel_data, label='Original Data')\n","plt.plot(chosen_pixel_data_subtracted, label='subtracted Data')\n","plt.plot(result.best_fit, label='Fitted Curve', linestyle='-')\n","plt.title('Fitted Curve and Original Data for Pixel {}'.format(chosen_pixel))\n","plt.xlabel('Z')\n","plt.ylabel('Intensity')\n","plt.legend()\n","plt.show()"],"metadata":{"id":"eVOFto3Q4XGb"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Reshape all data into proper format for parallel curve fitting\n","for i in range(len(data_list)):\n","    height, width, signal_dimension = data_list[i].shape\n","    data_list[i] = data_list[i].reshape(height * width, signal_dimension)"],"metadata":{"id":"HRGn9yDz4ai4"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Perform Parallelized Curve Fitting on Full Dataset"],"metadata":{"id":"H5pxjzSJFLIX"}},{"cell_type":"code","source":["def saveData(res, id):\n","    \"\"\"\n","    Function to save the peak fit parameters from the data to .csv files\n","\n","    Args:\n","        res: The peak fit parameters to be saved\n","        id: The oxidation time of the file to be saved\n","    Returns:\n","        True: If the files are saved successfully\n","    \"\"\"\n","    amplitude_map = np.array([])\n","    center_map = np.array([])\n","    sigma_map = np.array([])\n","    results = np.array(res)\n","\n","    for i in tqdm(range(len(results))):\n","        amplitude_map = np.append(amplitude_map, results[i][0])\n","        center_map = np.append(center_map, (results[i][1] + 550))\n","        sigma_map = np.append(sigma_map, results[i][2])\n","\n","    # Create folder titled 'Peak Parameter CSV Files' if it does not already exist\n","    try:\n","        np.savetxt(f'Peak Parameter CSV Files/{id}minAmp.csv', amplitude_map.reshape(300,300), delimiter=',')\n","        np.savetxt(f'Peak Parameter CSV Files/{id}minCenter.csv', center_map.reshape(300,300), delimiter=',')\n","        np.savetxt(f'Peak Parameter CSV Files/{id}minSigma.csv', sigma_map.reshape(300,300), delimiter=',')\n","    except:\n","        os.mkdir('Peak Parameter CSV Files')\n","        np.savetxt(f'Peak Parameter CSV Files/{id}minAmp.csv', amplitude_map.reshape(300,300), delimiter=',')\n","        np.savetxt(f'Peak Parameter CSV Files/{id}minCenter.csv', center_map.reshape(300,300), delimiter=',')\n","        np.savetxt(f'Peak Parameter CSV Files/{id}minSigma.csv', sigma_map.reshape(300,300), delimiter=',')\n","    return True\n","\n","def fit_all_curves_parallel(data_list, n_jobs=-1):\n","    \"\"\"\n","    Parallelized function to fit curves to the entire data set.\n","\n","    Args:\n","        data_list: The array of data arrays to be processed\n","        n_jobs: The number of jobs to run in parallel\n","    Returns:\n","        results: The peak fit parameters from the data\n","    \"\"\"\n","    results = Parallel(n_jobs=n_jobs)(\n","        delayed(manageData)(data)\n","        for data in tqdm(data_list, desc=\"Fitting Lorentzian curves\")\n","    )\n","    return results\n","\n","for i in range(len(data_list)):\n","    results = fit_all_curves_parallel(data_list[i], n_jobs=20)\n","    saveData(results, file_list[i][0:2])"],"metadata":{"id":"IFgwGLJD4b9z"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Load in Saved .csv Files"],"metadata":{"id":"Fk_N5azHFPt9"}},{"cell_type":"code","source":["def csv2num(csv):\n","    \"\"\"\n","    Function to convert all entries in .csv file to floats\n","\n","    Args:\n","        data_list: The array of data arrays to be processed\n","        n_jobs: The number of jobs to run in parallel\n","    Returns:\n","        results: The peak fit parameters from the data\n","    \"\"\"\n","    flattenedVec = csv.flatten()\n","    result = np.array([])\n","    for i in (range(len(flattenedVec))):\n","        result = np.append(result, float(flattenedVec[i]))\n","    return result\n","\n","def openFiles():\n","    \"\"\"\n","    Function to open the .csv files and convert them to numpy arrays.\n","\n","    Args:\n","        None\n","    Returns:\n","        amp_list: The array of amplitude data\n","        center_list: The array of center data\n","        width_list: The array of width data\n","    \"\"\"\n","    amp_list = []\n","    center_list = []\n","    width_list = []\n","\n","    for file in tqdm(os.listdir('Peak Parameter CSV Files')):\n","        if file.endswith('Amp.csv'):\n","            with open(file, 'r') as f:\n","                reader = csv.reader(f)\n","                data = list(reader)\n","                amp_data = np.array(data)\n","                amp = csv2num(amp_data).reshape(300,300)\n","                amp_list.append(amp)\n","\n","        elif file.endswith('Center.csv'):\n","            with open(file, 'r') as f:\n","                reader = csv.reader(f)\n","                data = list(reader)\n","                center_data = np.array(data)\n","                center = csv2num(center_data).reshape(300,300)\n","                center_list.append(center)\n","\n","        elif file.endswith('Sigma.csv'):\n","            with open(file, 'r') as f:\n","                reader = csv.reader(f)\n","                data = list(reader)\n","                sigma_data = np.array(data)\n","                sigma = csv2num(sigma_data).reshape(300,300)\n","                width_list.append(sigma)\n","\n","    return amp_list, center_list, width_list\n","\n","amplitudes, positions, widths = openFiles()"],"metadata":{"id":"pZ1_-RnL4mv5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Extract Parameter Evolution and Save to .csv"],"metadata":{"id":"rCXmd0mqFT4A"}},{"cell_type":"code","source":["def parAvg(data, xROI=20, yROI=20):\n","    \"\"\"\n","    Function to calculate the average peak fit parameters from the data\n","    using only a 20x20 region of pixels in the center of the triangle.\n","\n","    Args:\n","        data: The data array to be processed\n","        xROI: The number of pixels to use in the x direction\n","        yROI: The number of pixels to use in the y direction\n","    Returns:\n","        pars: The average peak fit parameters within the ROI\n","    \"\"\"\n","    pars = 0\n","    for x in range(xROI):\n","        for y in range(yROI):\n","            pars += data[140+x][140+y]\n","    return pars/(xROI*yROI)\n","\n","def getAveragePars(data):\n","    \"\"\"\n","    Function to take average of all peak fit parameters from the data\n","    for a given time step.\n","\n","    Args:\n","        data: The data array containing the peak fit parameters\n","    Returns:\n","        averagePar: The average peak fit parameters from the data\n","    \"\"\"\n","    averagePar = []\n","    for item in tqdm(data):\n","        averagePar.append(parAvg(item))\n","    return averagePar\n","\n","avgAmp = getAveragePars(amplitudes)\n","avgPos = getAveragePars(positions)\n","avgWidth = getAveragePars(widths)"],"metadata":{"id":"dd5w-lOs4ttS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Save these parameters to their own .csv files\n","try:\n","    np.savetxt(f'Average Parameters/Amplitudes.csv', avgAmp, delimiter=',')\n","    np.savetxt(f'Average Parameters/Positions.csv', avgPos, delimiter=',')\n","    np.savetxt(f'Average Parameters/Widths.csv', avgWidth, delimiter=',')\n","except:\n","    os.mkdir('Average Parameters')\n","    np.savetxt(f'Average Parameters/Amplitudes.csv', avgAmp, delimiter=',')\n","    np.savetxt(f'Average Parameters/Positions.csv', avgPos, delimiter=',')\n","    np.savetxt(f'Average Parameters/Widths.csv', avgWidth, delimiter=',')"],"metadata":{"id":"9pbBTVL24whm"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualize and Fit Curves to Parameter Evolution\n","\n","#### Use the functions generated by these peak fits in the synthetic data model."],"metadata":{"id":"98sKb3VJDj1Q"}},{"cell_type":"code","source":["avgAmp = np.genfromtxt('Average Parameters/Amplitudes.csv', delimiter=',')\n","avgPos = np.genfromtxt('Average Parameters/Positions.csv', delimiter=',')\n","avgWidth = np.genfromtxt('Average Parameters/Widths.csv', delimiter=',')"],"metadata":{"id":"BY2McaDuHEzD"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Peak Height"],"metadata":{"id":"EWimBlzfD237"}},{"cell_type":"code","source":["# Sample data\n","x = np.arange(0, 16)\n","\n","# Define the allometric function\n","def allometric(x, a, b, c):\n","    return a + (b * x**c)\n","\n","# Fit the allometric function to the data\n","params, covariance = curve_fit(allometric, x, avgAmp, maxfev=10000)\n","\n","a, b, c = params\n","\n","# Generate fitted values\n","y_fit = allometric(x, a, b, c)\n","\n","# Scatter plot\n","plt.scatter(x, avgAmp, label='Height', color='blue')\n","\n","# Plot the fitted allometric function\n","plt.plot(x, y_fit, label=f'Fitted Allometric', color='black', linestyle='dotted')\n","\n","# Add legend and limits\n","plt.legend()\n","plt.title('Height vs Oxidation Time')\n","plt.ylabel('Height')\n","plt.xlabel('Oxidation Time')\n","plt.xlim((-0.5, 15.5))\n","plt.show()\n","\n","# Print the parameters of the fitted function\n","print(f\"Fitted allometric function: y = {a} + {b:.2f}x^{c:.2f}\")"],"metadata":{"id":"_UN9xg5p4zfh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Peak Width"],"metadata":{"id":"l1_rp66YD44b"}},{"cell_type":"code","source":["# Sample data\n","x = np.arange(0, 16)\n","\n","# Define the allometric function\n","def allometric(x, a, b, c):\n","    return a + (b * x**c)\n","\n","# Fit the allometric function to the data\n","params, covariance = curve_fit(allometric, x, avgWidth, maxfev=10000)\n","\n","a, b, c = params\n","\n","# Generate fitted values\n","y_fit = allometric(x, a, b, c)\n","\n","# Scatter plot\n","plt.scatter(x, avgWidth, label='Width', color='blue')\n","\n","# Plot the fitted allometric function\n","plt.plot(x, y_fit, label=f'Fitted Allometric', color='black', linestyle='dotted')\n","\n","# Add legend and limits\n","plt.legend()\n","plt.title('Width vs Oxidation Time')\n","plt.ylabel('Width')\n","plt.xlabel('Oxidation Time')\n","plt.xlim((-0.5, 15.5))\n","plt.show()\n","\n","# Print the parameters of the fitted function\n","print(f\"Fitted allometric function: y = {a} + {b:.2f}x^{c:.2f}\")"],"metadata":{"id":"a_cam8Bl47TH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Peak Position"],"metadata":{"id":"txpIk6CJD63_"}},{"cell_type":"code","source":["# Sample data\n","x = np.arange(0, 16)\n","\n","# Define the allometric function\n","def allometric(x, a, b, c):\n","    return c + (a * x**b)\n","\n","# Fit the allometric function to the data\n","params, covariance = curve_fit(allometric, x, avgPos, maxfev=10000)\n","\n","a, b, c = params\n","\n","# Generate fitted values\n","y_fit = allometric(x, a, b, c)\n","\n","# Scatter plot\n","plt.scatter(x, avgPos, label='Position', color='blue')\n","\n","# Plot the fitted allometric function\n","plt.plot(x, y_fit, label=f'Fitted Allometric Function', color='black', linestyle='dotted')\n","\n","# Add legend and limits\n","plt.legend()\n","plt.title('Position vs Oxidation Time')\n","plt.ylabel('Position')\n","plt.xlabel('Oxidation Time')\n","plt.xlim((-0.5, 15.5))\n","plt.show()\n","\n","# Print the parameters of the fitted function\n","print(f\"Fitted allometric function: y = {c} + {a:.2f}x^{b:.2f}\")"],"metadata":{"id":"oYvMN_p549Ks"},"execution_count":null,"outputs":[]}]}