{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyPfz7ZUKIFZ1J2ni99hO/pl"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"markdown","source":["# Spectrum Processing and Model Testing\n","\n","##### This notebook is designed to be used to load in the files of interest to test the model. The first code block will utilize hyperspy to load in the 3D dataset as well as custom functions to remove calculation errors from the Hyperspectral Optical Microscope (HOM). Afterwards, Savitzky-Golay filtering was used to reduce the noise in the spectrum to more accurately mimic the synthetically generated data.\n","\n","#### This notebook can also be used to test the trained model on real, processed data, and output the metrics of merit to determine the success of the model."],"metadata":{"id":"KSXxP9djvXp6"}},{"cell_type":"markdown","source":["# Spectrum Processing"],"metadata":{"id":"k3FNarhBmk0V"}},{"cell_type":"code","source":["import hyperspy.api as hs\n","import hyperspy.signal_tools as hs_st\n","import hyperspy.axes as axes\n","from tqdm import tqdm\n","from scipy.signal import savgol_filter\n","import matplotlib.pyplot as plt\n","from Ground_Truth_Creator import getGT\n","from sklearn.metrics import root_mean_squared_error, mean_absolute_error\n","import os"],"metadata":{"id":"14tqT3AHztsc"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"p86etTLRmD4d"},"outputs":[],"source":["def loadFiles(title, size_arr, size_sel):\n","    \"\"\"\n","    Function to load the files and crop them to the correct size.\n","\n","    Args:\n","        title: The title of the file to be loaded\n","        size_arr: The array containing the size of the crop\n","        size_sel: The index of the size\n","    Returns:\n","        s0.data: 3D Hyperspy data array of size (300, 300, n_wavelengths)\n","    \"\"\"\n","    s0 = hs.load(title) # Load the file\n","    s0.data = s0.data[::-1] # The file needs to be transposed to solve an issue with the array dimensions.\n","\n","    s0.crop(1,size_arr[size_sel][0][0], size_arr[size_sel][0][1])\n","    s0.crop(2,size_arr[size_sel][1][0], size_arr[size_sel][1][1])\n","\n","    # set titles and name variables.\n","    s0 = s0.as_signal1D(0)\n","    s0.axes_manager[0].name = \"width\"\n","    s0.axes_manager[1].name = \"height\"\n","    s0.axes_manager[2].name = \"wavelength\"\n","    s0.axes_manager[0].units = \"pix\"\n","    s0.axes_manager[1].units = \"pix\"\n","    s0.axes_manager[2].units = \"nm\"\n","    s0.axes_manager[2].offset = 200\n","    s0.axes_manager[2].scale = 4\n","\n","    return s0.data\n","\n","def removeIssuePoint1(data):\n","    \"\"\"\n","    First function to remove miscalculation error from HOM if the dataset\n","    contains less than 151 points on the wavelength axis.\n","\n","    Args:\n","        data: The data array to be processed (len)\n","    Returns:\n","        data: The data array after correcting the miscalculation (len)\n","    \"\"\"\n","    for x in range(len(data)):\n","        for y in range(len(data[0])):\n","            curMax = np.max(data[x][y])\n","            for z in range(len(data[0][0])):\n","                if data[x][y][z] == curMax:\n","                    data[x][y][z] = data[x][y][z-1] # Replace the miscalculation with the previous value\n","                    break\n","    return data\n","\n","def removeIssuePoint2(data):\n","    \"\"\"\n","    Second function to remove miscalculation error from HOM if the dataset\n","    contains more than 151 points on the wavelength axis.\n","\n","    Args:\n","        data: The data array to be processed (len)\n","    Returns:\n","        data: The data array after correcting the miscalculation (len - 1)\n","    \"\"\"\n","    for x in range(len(data)):\n","        for y in range(len(data[0])):\n","            curMax = np.max(data[x][y])\n","            for z in range(len(data[0][0])):\n","                if data[x][y][z] == curMax:\n","                    index = z\n","                    break\n","            break\n","        break\n","    data = np.delete(data, index, 2) # Delete the miscalculation for dataset\n","    return data\n","\n","def removeIssuePoint3(data):\n","    \"\"\"\n","    Function to ensure the length of the final array is 150 along the wavelength axis.\n","\n","    Args:\n","        data: The data array to be processed (len > 150)\n","    Returns:\n","        data: The data array after correcting the miscalculation (len = 150)\n","    \"\"\"\n","    while len(data[0][0]) > 150:\n","        data = np.delete(data, -1, 2)\n","    return data\n","\n","def subtract_background(data):\n","    \"\"\"\n","    Subtract the background signal from the DRS data. Use the first 20 and last 20\n","    points of the spectrum to calculate the background signal.\n","\n","    Args:\n","        data: The data array to be processed\n","    Returns:\n","        data: Background subtracted data array of the same length\n","    \"\"\"\n","    limits = np.arange(len(data[0][0]))\n","    for x in range(len(data)):\n","        for y in range(len(data[0])):\n","            background_indices = np.concatenate((np.arange(20), np.arange(-20, 0)))  # Indices for the background points\n","            background_x = limits[background_indices]\n","            background_y = data[x][y][background_indices]\n","            background_params = np.polyfit(background_x, background_y, 1)  # Fit a line\n","            background = np.polyval(background_params, limits)\n","            data[x][y] = data[x][y] - background\n","    return data\n","\n","def SGprocess(data):\n","    \"\"\"\n","    Function to process the data using the Savitzky-Golay filter of window size = 5\n","    and polynomial order = 5.\n","\n","    Args:\n","        data: The data array to be processed\n","    Returns:\n","        standard_SG: Savitzky-Golay processed data array reshaped into original dimensions (n_x, n_y, n_wavelengths)\n","    \"\"\"\n","    data = data.reshape(90000, 150)\n","    standard_SG = savgol_filter(data, 50, 5, mode='constant') # Apply the Savitzky-Golay filter with constant mode to ensure wavelength axis is not altered\n","    return standard_SG.reshape(300, 300, 150)\n","\n","def load_and_process_data(file, size_arr, size_sel):\n","    \"\"\"\n","    Function to load and pre-process the data array from the original filename.\n","\n","    Args:\n","        file: The filename of the data to be processed\n","    Returns:\n","        final_data: The final processed data array\n","    \"\"\"\n","    data = loadFiles(file, size_arr, size_sel)\n","    if len(data[0][0]) < 151:\n","        final_data = SGprocess(subtract_background(removeIssuePoint1(data)))\n","    elif len(data[0][0]) > 151:\n","        final_data = SGprocess(subtract_background(removeIssuePoint3(removeIssuePoint2(data))))\n","    else:\n","        final_data = SGprocess(subtract_background(removeIssuePoint2(data)))\n","    return final_data\n","\n","# Global variables to find triangle of interest from full image\n","size_sel_gb = 1\n","size_arr_gb = [[[345 ,350], [810, 815]], [[216, 516], [675, 975]], [[222, 495], [672, 972]]]\n","\n","data_list = []\n","\n","# Non pre-processed data\n","example_spectrum = loadFiles(\"Time Series Oxidation Files/00minUVO_WS2_550-700_1nmsteps_150ms-1 (1).tif\", size_arr_gb, size_sel_gb)\n","\n","# Load in all pre-processed data\n","for file in os.listdir('Time Series Oxidation Files'):\n","    if file.endswith('.tif'):\n","        print(file)\n","        data_list.append(load_and_process_data(file, size_arr_gb, size_sel_gb))\n","\n","# Use GT function to get the ground truth classification result\n","ground_truth_list = []\n","for item in os.listdir('Time Series Oxidation Files'):\n","    if item.endswith('.tif'):\n","        ground_truth_list.append(getGT(item))"]},{"cell_type":"markdown","source":["# Visualize Spectrum"],"metadata":{"id":"L_DDlZq9mv0g"}},{"cell_type":"code","source":["x, y = 150,150\n","plt.plot(example_spectrum[y][x], c='red', label='BG Subtracted Curve')\n","plt.plot(data_list[0][y][x], c='blue', label='SG Filtered and BG Subtracted Curve')\n","plt.title(\"Example Spectrum with SG Filtering and Background Subtraction\")\n","plt.xlabel(\"Wavelength (nm)\")\n","plt.ylabel(\"Intensity\")\n","plt.legend()\n","plt.show()"],"metadata":{"id":"KjP8iNHFmvk0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Testing the Model"],"metadata":{"id":"MOeiZKy6m1sD"}},{"cell_type":"code","source":["def visualizeModel(data, classification_threshold = 0.995):\n","    \"\"\"\"\n","    Function to visualize the model output for a given dataset\n","\n","    Args:\n","        model: The trained model to be used for inference\n","        data: The dataset to be used for inference\n","        classification_threshold: The threshold for classification\n","    Returns:\n","        material_mask: The binary material mask containing the classification results\n","        dopant_map: The dopant map containing the regression results\n","    \"\"\"\n","    assert(len(data[0][0]) == 150)\n","    Y_sel, X_sel, W_sel = data.shape\n","\n","    # Flatten spatial dimension for inference\n","    X_input = data.reshape((Y_sel * X_sel, W_sel))\n","    X_input = X_input[..., np.newaxis]\n","\n","    classification_pred, regression_pred = model.predict(X_input, batch_size=32)\n","    classification_map = classification_pred.reshape((Y_sel, X_sel))\n","    dopant_map = regression_pred.reshape((Y_sel, X_sel))\n","\n","    material_mask = (classification_map > classification_threshold).astype(float)\n","    dopant_map[material_mask == 0] = np.nan\n","\n","    return material_mask, dopant_map\n","\n","classification_results = []\n","regression_results = []\n","counter = 0\n","\n","# Load in the trained model\n","model = tf.keras.models.load_model('Oxidation_Model/Ox_Class_Model.h5')\n","\n","for data in data_list:\n","    print(f\"File Number {counter}\")\n","    model_result = visualizeModel(data)\n","    classification_results.append(model_result[0])\n","    regression_results.append(model_result[1])\n","    counter += 1"],"metadata":{"id":"yDfEdcMtm3eh"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Visualize Results"],"metadata":{"id":"vGCs1cgHnQDI"}},{"cell_type":"code","source":["time_step = 0\n","plt.figure(figsize=(14, 10))\n","\n","plt.subplot(2,2,1)\n","plt.imshow(classification_results[time_step], cmap='gray')\n","plt.title('Material (white) vs Substrate (black)')\n","plt.colorbar()\n","\n","plt.subplot(2, 2, 2)\n","plt.imshow(regression_results[time_step], cmap='inferno')\n","plt.title('Oxidation Map (2D regions)')\n","plt.colorbar()\n","\n","plt.show()\n","\n","print(f\"Example Oxidation Percentage: {regression_results[time_step][150][150]}\")\n","print(f\"Example Classification (1): {classification_results[time_step][150][150]}\")\n","print(f\"Example Classification (0): {classification_results[time_step][0][0]}\")"],"metadata":{"id":"R7cB0rXpnShd"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Model Evaluation"],"metadata":{"id":"0lKfFXiYnpxV"}},{"cell_type":"markdown","source":["### Classification Results"],"metadata":{"id":"0HD6P8drnxFw"}},{"cell_type":"code","source":["def getAccuracyScore(Prediction, gt_Data):\n","    \"\"\"\n","    Function to calculate the accuracy score of the model\n","\n","    Args:\n","        Prediction: The predicted data\n","        gt_Data: The ground truth data\n","    Returns:\n","        correct / len(gt_Data): The accuracy score\n","    \"\"\"\n","    Prediction = Prediction.flatten()\n","    assert(len(gt_Data) == len(Prediction))\n","    correct = 0\n","    for i in range(len(gt_Data)):\n","        if gt_Data[i] == Prediction[i]:\n","            correct += 1\n","    return correct / len(gt_Data)\n","\n","accuracy_scores = []\n","for i in range(len(classification_results)):\n","    accuracy_scores.append(getAccuracyScore(classification_results[i], ground_truth_list[i]))\n","\n","print(np.round(accuracy_scores, 4))"],"metadata":{"id":"eyZ9ryD6nsEF"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["### Regression Results"],"metadata":{"id":"mRhP7Q_Dnzfr"}},{"cell_type":"code","source":["def getMedian(oxidation_map):\n","    \"\"\"\n","    Function to calculate the median of the oxidation map\n","\n","    Args:\n","        oxidation_map: The oxidation map to be used\n","    Returns:\n","        np.median(clean_map): The median of the oxidation map\n","    \"\"\"\n","    oxidation_map = oxidation_map.flatten()\n","    clean_map = oxidation_map[~np.isnan(oxidation_map)]\n","    return np.median(clean_map)\n","\n","medianVals = []\n","for time in regression_results:\n","    medianVals.append(getMedian(time))\n","\n","print(np.round(medianVals, 4))"],"metadata":{"id":"hbpVx_nXn1_r"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["y0 = np.float32(0)\n","x = np.arange(0, 16, 1)\n","slope, _, _, _ = np.linalg.lstsq(x[:, np.newaxis], medianVals - y0, rcond=None)\n","y_fit = y0 + slope * x\n","\n","# Calculate R-squared\n","y_mean = np.mean(medianVals)\n","ss_tot = np.sum((medianVals - y_mean) ** 2)\n","ss_res = np.sum((medianVals - y_fit) ** 2)\n","r_squared = 1 - (ss_res / ss_tot)\n","\n","print(f\"R² value: {r_squared:.4f}\")\n","RMSE = root_mean_squared_error(x, medianVals)\n","MAE = mean_absolute_error(x, medianVals)\n","print(f\"RMSE: {np.round(RMSE, 4)}\")\n","print(f\"MAE: {np.round(MAE, 4)}\")\n","\n","# Plot the fitted line with R² in legend\n","plt.plot(x, y_fit, label=f'Fitted Line (R² = {r_squared:.4f})', color='red')\n","plt.scatter(x, medianVals, c='black', marker='s', )\n","plt.xlabel('Ground Truth Oxidation Time')\n","plt.ylabel('Predicted Oxidation Time')\n","plt.show()"],"metadata":{"id":"ZHnceYx8n7N7"},"execution_count":null,"outputs":[]}]}